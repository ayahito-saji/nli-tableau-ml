{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d5f9f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import pickle\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cdb295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./config.json\", \"r\") as fp:\n",
    "    config = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3811d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_PATH = config[\"data_dir_path\"]\n",
    "LABEL_DICT = config[\"label_dict\"]\n",
    "WORD_EMBEDDINGS_PATH = os.path.join(DATA_DIR_PATH, \"glove.840B.300d.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801d2cf",
   "metadata": {},
   "source": [
    "# Generate Word Index Map and Word Embedding Matrix from UD Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f1d4ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>udtree1</th>\n",
       "      <th>udtree2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is training his horse for a competition.</td>\n",
       "      <td>&lt;dt word=\"jumps\" lemma=\"jump\" dependency=\"root...</td>\n",
       "      <td>&lt;dt word=\"training\" lemma=\"train\" dependency=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is at a diner, ordering an omelette.</td>\n",
       "      <td>&lt;dt word=\"jumps\" lemma=\"jump\" dependency=\"root...</td>\n",
       "      <td>&lt;dt word=\"diner\" lemma=\"diner\" dependency=\"roo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entailment</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is outdoors, on a horse.</td>\n",
       "      <td>&lt;dt word=\"jumps\" lemma=\"jump\" dependency=\"root...</td>\n",
       "      <td>&lt;dt word=\"outdoors\" lemma=\"outdoors\" dependenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>They are smiling at their parents</td>\n",
       "      <td>&lt;dt word=\"children\" lemma=\"childre\" dependency...</td>\n",
       "      <td>&lt;dt word=\"smiling\" lemma=\"smil\" dependency=\"ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entailment</td>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>There are children present</td>\n",
       "      <td>&lt;dt word=\"children\" lemma=\"childre\" dependency...</td>\n",
       "      <td>&lt;dt word=\"are\" lemma=\"be\" dependency=\"root\" up...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label                                          sentence1  \\\n",
       "0        neutral  A person on a horse jumps over a broken down a...   \n",
       "1  contradiction  A person on a horse jumps over a broken down a...   \n",
       "2     entailment  A person on a horse jumps over a broken down a...   \n",
       "3        neutral              Children smiling and waving at camera   \n",
       "4     entailment              Children smiling and waving at camera   \n",
       "\n",
       "                                           sentence2  \\\n",
       "0  A person is training his horse for a competition.   \n",
       "1      A person is at a diner, ordering an omelette.   \n",
       "2                  A person is outdoors, on a horse.   \n",
       "3                  They are smiling at their parents   \n",
       "4                         There are children present   \n",
       "\n",
       "                                             udtree1  \\\n",
       "0  <dt word=\"jumps\" lemma=\"jump\" dependency=\"root...   \n",
       "1  <dt word=\"jumps\" lemma=\"jump\" dependency=\"root...   \n",
       "2  <dt word=\"jumps\" lemma=\"jump\" dependency=\"root...   \n",
       "3  <dt word=\"children\" lemma=\"childre\" dependency...   \n",
       "4  <dt word=\"children\" lemma=\"childre\" dependency...   \n",
       "\n",
       "                                             udtree2  \n",
       "0  <dt word=\"training\" lemma=\"train\" dependency=\"...  \n",
       "1  <dt word=\"diner\" lemma=\"diner\" dependency=\"roo...  \n",
       "2  <dt word=\"outdoors\" lemma=\"outdoors\" dependenc...  \n",
       "3  <dt word=\"smiling\" lemma=\"smil\" dependency=\"ro...  \n",
       "4  <dt word=\"are\" lemma=\"be\" dependency=\"root\" up...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_snli_train = pd.read_csv(os.path.join(DATA_DIR_PATH, \"snli_train.tsv\"), delimiter='\\t', index_col=0)\n",
    "df_snli_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9345963c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc0a50f0f5b45368c6ec8d482c0f8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/549361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "11352021"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = []\n",
    "for sample in tqdm(list(df_snli_train.itertuples())):\n",
    "    word_list.extend(tree2tokenlist(ET.fromstring(sample.udtree1)))\n",
    "    word_list.extend(tree2tokenlist(ET.fromstring(sample.udtree2)))\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aedc29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37997"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(word_list)\n",
    "\n",
    "word2index = {}\n",
    "\n",
    "word2index[\"_PAD_\"] = 0\n",
    "word2index[\"_OOV_\"] = 1\n",
    "\n",
    "offset = 2\n",
    "\n",
    "for i, word in enumerate(counts.most_common()):\n",
    "    word2index[word[0]] = i + offset\n",
    "len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "626a8e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34689"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = {}\n",
    "\n",
    "with open(WORD_EMBEDDINGS_PATH, \"r\") as fp:\n",
    "    for line in fp:\n",
    "        line = line.split()\n",
    "\n",
    "        try:\n",
    "            float(line[1])\n",
    "            word = line[0]\n",
    "            if word in word2index:\n",
    "                embeddings[word] = np.array(line[1:], dtype=float)\n",
    "\n",
    "        except ValueError:\n",
    "            pass\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a866b2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing words: 3306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37997, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word2index) # 埋め込みの単語数\n",
    "embedding_size = len(list(embeddings.values())[0]) # 単語埋め込みの次元数\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_size)) # 埋め込み行列(単語数×埋め込み次元数)\n",
    "\n",
    "missing_words = []\n",
    "for word, index in word2index.items():\n",
    "    if word in embeddings:\n",
    "        embedding_matrix[index] = embeddings[word]\n",
    "    else:\n",
    "        if word == \"_PAD_\":\n",
    "            continue\n",
    "        if word != \"_OOV_\":\n",
    "            missing_words.append(word)\n",
    "        embedding_matrix[index] = np.random.normal(size=(embedding_size))\n",
    "\n",
    "print(\"The number of missing words:\", len(missing_words))\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62c62f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR_PATH, \"word_index_map.json\"), \"w\") as fp:\n",
    "    json.dump(word2index, fp, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9a81527",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR_PATH, \"word_embedding_matrix.pkl\"), \"wb\") as fp:\n",
    "    pickle.dump(embedding_matrix, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcdf999",
   "metadata": {},
   "source": [
    "# Generate Train Dataset, Dev Dataset, Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0fe2735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>udtree1</th>\n",
       "      <th>udtree2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Two women are embracing while holding to go pa...</td>\n",
       "      <td>The sisters are hugging goodbye while holding ...</td>\n",
       "      <td>&lt;dt word=\"embracing\" lemma=\"embrace\" dependenc...</td>\n",
       "      <td>&lt;dt word=\"hugging\" lemma=\"hugg\" dependency=\"ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entailment</td>\n",
       "      <td>Two women are embracing while holding to go pa...</td>\n",
       "      <td>Two woman are holding packages.</td>\n",
       "      <td>&lt;dt word=\"embracing\" lemma=\"embrace\" dependenc...</td>\n",
       "      <td>&lt;dt word=\"holding\" lemma=\"hold\" dependency=\"ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>Two women are embracing while holding to go pa...</td>\n",
       "      <td>The men are fighting outside a deli.</td>\n",
       "      <td>&lt;dt word=\"embracing\" lemma=\"embrace\" dependenc...</td>\n",
       "      <td>&lt;dt word=\"fighting\" lemma=\"fight\" dependency=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entailment</td>\n",
       "      <td>Two young children in blue jerseys, one with t...</td>\n",
       "      <td>Two kids in numbered jerseys wash their hands.</td>\n",
       "      <td>&lt;dt word=\"standing\" lemma=\"stand\" dependency=\"...</td>\n",
       "      <td>&lt;dt word=\"wash\" lemma=\"wash\" dependency=\"root\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Two young children in blue jerseys, one with t...</td>\n",
       "      <td>Two kids at a ballgame wash their hands.</td>\n",
       "      <td>&lt;dt word=\"standing\" lemma=\"stand\" dependency=\"...</td>\n",
       "      <td>&lt;dt word=\"wash\" lemma=\"wash\" dependency=\"root\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label                                          sentence1  \\\n",
       "0        neutral  Two women are embracing while holding to go pa...   \n",
       "1     entailment  Two women are embracing while holding to go pa...   \n",
       "2  contradiction  Two women are embracing while holding to go pa...   \n",
       "3     entailment  Two young children in blue jerseys, one with t...   \n",
       "4        neutral  Two young children in blue jerseys, one with t...   \n",
       "\n",
       "                                           sentence2  \\\n",
       "0  The sisters are hugging goodbye while holding ...   \n",
       "1                    Two woman are holding packages.   \n",
       "2               The men are fighting outside a deli.   \n",
       "3     Two kids in numbered jerseys wash their hands.   \n",
       "4           Two kids at a ballgame wash their hands.   \n",
       "\n",
       "                                             udtree1  \\\n",
       "0  <dt word=\"embracing\" lemma=\"embrace\" dependenc...   \n",
       "1  <dt word=\"embracing\" lemma=\"embrace\" dependenc...   \n",
       "2  <dt word=\"embracing\" lemma=\"embrace\" dependenc...   \n",
       "3  <dt word=\"standing\" lemma=\"stand\" dependency=\"...   \n",
       "4  <dt word=\"standing\" lemma=\"stand\" dependency=\"...   \n",
       "\n",
       "                                             udtree2  \n",
       "0  <dt word=\"hugging\" lemma=\"hugg\" dependency=\"ro...  \n",
       "1  <dt word=\"holding\" lemma=\"hold\" dependency=\"ro...  \n",
       "2  <dt word=\"fighting\" lemma=\"fight\" dependency=\"...  \n",
       "3  <dt word=\"wash\" lemma=\"wash\" dependency=\"root\"...  \n",
       "4  <dt word=\"wash\" lemma=\"wash\" dependency=\"root\"...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_snli_dev = pd.read_csv(os.path.join(DATA_DIR_PATH, \"snli_dev.tsv\"), delimiter='\\t', index_col=0)\n",
    "df_snli_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09700025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(df):\n",
    "    id_list = []\n",
    "    premise_list = []\n",
    "    hypothesis_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for sample in tqdm(list(df.itertuples())):\n",
    "        id_list.append(sample.Index)\n",
    "        premise_list.append(tokenlist2indexlist(tree2tokenlist(ET.fromstring(sample.udtree1)), word2index))\n",
    "        hypothesis_list.append(tokenlist2indexlist(tree2tokenlist(ET.fromstring(sample.udtree2)), word2index))\n",
    "        label_list.append(LABEL_DICT[sample.gold_label])\n",
    "        \n",
    "    return {\n",
    "        \"ids\": id_list,\n",
    "        \"premises\": premise_list,\n",
    "        \"hypotheses\": hypothesis_list,\n",
    "        \"labels\": label_list\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dbe6415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c5766d56bd4a549b252edc5a4712bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/549361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = df_to_dataset(df_snli_train)\n",
    "with open(os.path.join(DATA_DIR_PATH, \"train_data.pkl\"), \"wb\") as fp:\n",
    "    pickle.dump(train_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f33b55cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1747e48ad5243dc8db49ee0b1d108c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9842 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_data = df_to_dataset(df_snli_dev)\n",
    "with open(os.path.join(DATA_DIR_PATH, \"dev_data.pkl\"), \"wb\") as fp:\n",
    "    pickle.dump(dev_data, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
