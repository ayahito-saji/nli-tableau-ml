{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ea4496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8663fefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./config.json\", \"r\") as fp:\n",
    "    config = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a012f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_PATH = config[\"data_dir_path\"]\n",
    "LABEL_DICT = config[\"label_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59574e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_NAME = \"snli_test.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d797b196",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf2459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR_PATH, DF_NAME), delimiter='\\t', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c669669",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_df = df[(df.entailment_tableau_size > 2) & (df.contradiction_tableau_size > 2)]\n",
    "decomposed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80da35bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "undecomposed_df = df[(df.entailment_tableau_size == 2) & (df.contradiction_tableau_size == 2)]\n",
    "undecomposed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c59332",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decomposed Sample Rate:\", len(decomposed_df) / len(df))\n",
    "print(\"Undecomposed Sample Rate:\", len(undecomposed_df) / len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53c729",
   "metadata": {},
   "source": [
    "# Define The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d168508",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DF = decomposed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7886362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daf7e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a94b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/word_index_map.json\", \"r\") as worddict_file:\n",
    "    worddict = json.load(worddict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c992d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esim.data import Preprocessor\n",
    "preprocessor = Preprocessor(lowercase=False,\n",
    "                            ignore_punctuation=False,\n",
    "                            num_words=None,\n",
    "                            stopwords={},\n",
    "                            labeldict=LABEL_DICT,\n",
    "                            bos=None,\n",
    "                            eos=None)\n",
    "preprocessor.worddict = worddict\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6db7a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"./data/checkpoints/best.pth.tar\")\n",
    "\n",
    "# Retrieving model parameters from checkpoint.\n",
    "vocab_size = checkpoint[\"model\"][\"_word_embedding.weight\"].size(0)\n",
    "embedding_dim = checkpoint[\"model\"]['_word_embedding.weight'].size(1)\n",
    "hidden_size = checkpoint[\"model\"][\"_projection.0.weight\"].size(0)\n",
    "num_classes = checkpoint[\"model\"][\"_classification.4.weight\"].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6229472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esim.model import ESIM\n",
    "\n",
    "model = ESIM(vocab_size,\n",
    "             embedding_dim,\n",
    "             hidden_size,\n",
    "             num_classes=num_classes,\n",
    "             device=device).to(device)\n",
    "model.load_state_dict(checkpoint[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08544ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict(premises, hypothesises):\n",
    "    premises_split = []\n",
    "    for premise in premises:\n",
    "        if type(premise) is list:\n",
    "            premises_split.append(premise)\n",
    "        else:\n",
    "            premises_split.append([w for w in premise.rstrip().split()])\n",
    "\n",
    "    hypothesises_split = []\n",
    "    for hypothesis in hypothesises:\n",
    "        if type(hypothesis) is list:\n",
    "            hypothesises_split.append(hypothesis)\n",
    "        else:\n",
    "            hypothesises_split.append([w for w in hypothesis.rstrip().split()])\n",
    "    \n",
    "    transformed_premises = [preprocessor.words_to_indices(premise_split) for premise_split in premises_split]\n",
    "    transformed_hypothesises = [preprocessor.words_to_indices(hypothesis_split) for hypothesis_split in hypothesises_split]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for start_index in range(0, len(transformed_premises), batch_size):\n",
    "            premises_batch = transformed_premises[start_index: start_index+batch_size]\n",
    "            premises_len_batch = [len(premise) for premise in premises_batch]\n",
    "            max_of_premises_len_batch = max(premises_len_batch)\n",
    "            \n",
    "            premises_batch_tensor = torch.ones((len(premises_batch), max_of_premises_len_batch), dtype=torch.long) * 0\n",
    "\n",
    "            for i, premise in enumerate(premises_batch):\n",
    "                end = premises_len_batch[i]\n",
    "                premises_batch_tensor[i][:end] = torch.tensor(premise[:end])\n",
    "            \n",
    "            hypothesises_batch = transformed_hypothesises[start_index: start_index+batch_size]\n",
    "            hypothesises_len_batch = [len(hypothesis) for hypothesis in hypothesises_batch]\n",
    "            max_of_hypothesises_len_batch = max(hypothesises_len_batch)\n",
    "\n",
    "            hypothesises_batch_tensor = torch.ones((len(hypothesises_batch), max_of_hypothesises_len_batch), dtype=torch.long) * 0\n",
    "\n",
    "            for i, hypothesis in enumerate(hypothesises_batch):\n",
    "                end = hypothesises_len_batch[i]\n",
    "                hypothesises_batch_tensor[i][:end] = torch.tensor(hypothesis[:end])\n",
    "            \n",
    "            _, probs = model(\n",
    "                premises_batch_tensor.to(device),\n",
    "                torch.tensor(premises_len_batch).to(device),\n",
    "                hypothesises_batch_tensor.to(device),\n",
    "                torch.tensor(hypothesises_len_batch).to(device)\n",
    "            )\n",
    "            results_batch = [prob.cpu().numpy() for prob in probs]\n",
    "            results.extend(results_batch)\n",
    "    return np.array(results)\n",
    "            \n",
    "predict([\"I like tomatos\", [\"I\", \"like\", \"tomatos\"]],\n",
    "        [\"I do n't like tomatos\", [\"I\", \"do\", \"n't\", \"like\", \"tomatos\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c1d5f",
   "metadata": {},
   "source": [
    "# ANSWER WITH NORMAL ESIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "premises = [\" \".join(tree2tokenlist(sample.udtree1)) for sample in TARGET_DF.itertuples()]\n",
    "hypothesises = [\" \".join(tree2tokenlist(sample.udtree2)) for sample in TARGET_DF.itertuples()]\n",
    "\n",
    "gold_labels = np.array([LABEL_DICT[sample.gold_label] for sample in TARGET_DF.itertuples()])\n",
    "simple_predicted_labels = predict(premises, hypothesises).argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c761a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"acc: {:.3f}%\".format(100 * (simple_predicted_labels == gold_labels).sum() / len(TARGET_DF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44bceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(gold_labels, simple_predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741faa30",
   "metadata": {},
   "source": [
    "# ANSWER WITH TABLEAU WITH ESIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d7ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_tableau(tableau, premise_list, hypothesis_list):\n",
    "    entry_list = []\n",
    "    child_entries_list = []\n",
    "    contradictable_entries_pair_list = []\n",
    "    all_branches = []\n",
    "    \n",
    "    def append_entry_list(node):\n",
    "        entry_offset = len(entry_list)\n",
    "        entry_size = 0\n",
    "        for entry in node[\"entries\"]:\n",
    "            entry_list.append(entry)\n",
    "            child_entries_list.append([entry_offset + entry_size + 1])\n",
    "            entry_size += 1\n",
    "\n",
    "        childtree = []\n",
    "        for child_node in node[\"child_nodes\"]:\n",
    "            childtree.append(append_entry_list(child_node))\n",
    "        child_entries_list[entry_offset + entry_size - 1] = childtree\n",
    "        return entry_offset\n",
    "\n",
    "    def append_contradictable_entries_pair_list(entry_index):\n",
    "        subtree_entry_indices = []\n",
    "        for child_entry_index in child_entries_list[entry_index]:\n",
    "            subtree_entry_indices.extend(append_contradictable_entries_pair_list(child_entry_index))\n",
    "\n",
    "        if entry_list[entry_index][\"exist_eq_entries\"] == False:\n",
    "            for subtree_entry_index in subtree_entry_indices:\n",
    "                if entry_list[entry_index][\"origin\"] != entry_list[subtree_entry_index][\"origin\"]:\n",
    "                    if entry_list[entry_index][\"sign\"] == True and entry_list[subtree_entry_index][\"sign\"] == False:\n",
    "                        contradictable_entries_pair_list.append((entry_index, subtree_entry_index))\n",
    "                    elif entry_list[entry_index][\"sign\"] == False and entry_list[subtree_entry_index][\"sign\"] == True:\n",
    "                        contradictable_entries_pair_list.append((subtree_entry_index, entry_index))\n",
    "                    elif entry_list[entry_index][\"sign\"] == True and entry_list[subtree_entry_index][\"sign\"] == True:\n",
    "                        contradictable_entries_pair_list.append((entry_index, subtree_entry_index))\n",
    "\n",
    "            subtree_entry_indices.append(entry_index)\n",
    "        return subtree_entry_indices\n",
    "\n",
    "    def calculate_branch(entry_index):\n",
    "        if len(child_entries_list[entry_index]) == 0:\n",
    "            return [{entry_index}]\n",
    "\n",
    "        branches = []\n",
    "        for child_entry_index in child_entries_list[entry_index]:\n",
    "            branches.extend(calculate_branch(child_entry_index))\n",
    "        for branch in branches:\n",
    "            branch.add(entry_index)\n",
    "        return branches\n",
    "\n",
    "    append_entry_list(tableau[\"root\"])\n",
    "    append_contradictable_entries_pair_list(0)\n",
    "    all_branches = calculate_branch(0)\n",
    "    # entry_list, child_entries_list, contradictable_enttries_pair_list, all_branchesを計算した\n",
    "\n",
    "    all_sentence_list = [tree2tokenlist(ET.fromstring(entry[\"tree\"])) for entry in entry_list]\n",
    "    \n",
    "    def findadd_sentence_pair(premise, hypothesis):\n",
    "        for i, _premise in enumerate(premise_list):\n",
    "            _hypothesis = hypothesis_list[i]\n",
    "            if premise == _premise and hypothesis == _hypothesis:\n",
    "                return i\n",
    "        premise_list.append(premise)\n",
    "        hypothesis_list.append(hypothesis)\n",
    "        return len(premise_list) - 1\n",
    "    \n",
    "    contradiction_labels = []\n",
    "    sentence_pair_row = []\n",
    "\n",
    "    for i, pair in enumerate(contradictable_entries_pair_list):\n",
    "        if entry_list[pair[0]][\"sign\"] == True and entry_list[pair[1]][\"sign\"] == False:\n",
    "            contradiction_labels.append(LABEL_DICT[\"entailment\"])\n",
    "        elif entry_list[pair[0]][\"sign\"] == True and entry_list[pair[1]][\"sign\"] == True:\n",
    "            contradiction_labels.append(LABEL_DICT[\"contradiction\"])\n",
    "        sentence_pair_row.append(findadd_sentence_pair(all_sentence_list[pair[0]],\n",
    "                                                       all_sentence_list[pair[1]]))\n",
    "    \n",
    "    return {\n",
    "        \"branches\": all_branches,\n",
    "        \"pairs\": contradictable_entries_pair_list,\n",
    "        \"sentence_pair_row\": sentence_pair_row,\n",
    "        \"contradiction_labels\": torch.Tensor(contradiction_labels).to(device)\n",
    "    }\n",
    "\n",
    "def transform_sample(df):\n",
    "    transformed_sample_list = []\n",
    "    \n",
    "    for sample in df.itertuples():\n",
    "        premise_list = []\n",
    "        hypothesis_list = []\n",
    "\n",
    "        transformed_sample = {}\n",
    "        transformed_sample[\"gold_label\"] = LABEL_DICT[sample.gold_label]\n",
    "        transformed_sample[\"entailment_tableau\"] = transform_tableau(json.loads(sample.entailment_tableau),\n",
    "                                                                     premise_list,\n",
    "                                                                     hypothesis_list)\n",
    "        transformed_sample[\"contradiction_tableau\"] = transform_tableau(json.loads(sample.contradiction_tableau),\n",
    "                                                                        premise_list,\n",
    "                                                                        hypothesis_list)\n",
    "        transformed_sample[\"premises\"] = premise_list\n",
    "        transformed_sample[\"hypothesises\"] = hypothesis_list\n",
    "        transformed_sample[\"premise\"] = sample.sentence1\n",
    "        transformed_sample[\"hypothesis\"] = sample.sentence2\n",
    "        \n",
    "        sentence_pair_size = len(premise_list)\n",
    "        transformed_sample[\"sentence_pair_size\"] = sentence_pair_size\n",
    "\n",
    "        transformed_sample[\"entailment_tableau\"][\"sentence_pair_row\"] = (torch.eye(sentence_pair_size)[transformed_sample[\"entailment_tableau\"][\"sentence_pair_row\"]]).to(device)\n",
    "        transformed_sample[\"contradiction_tableau\"][\"sentence_pair_row\"] = (torch.eye(sentence_pair_size)[transformed_sample[\"contradiction_tableau\"][\"sentence_pair_row\"]]).to(device)\n",
    "        \n",
    "        \n",
    "        transformed_sample_list.append(transformed_sample)\n",
    "    return transformed_sample_list\n",
    "        \n",
    "target_dataset = transform_sample(TARGET_DF)\n",
    "print(view_tableau(TARGET_DF.iloc[0].entailment_tableau))\n",
    "target_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e149938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def is_close_tableau(tableau, r):\n",
    "    if len(tableau[\"sentence_pair_row\"]) == 0:\n",
    "        return False\n",
    "\n",
    "    is_contradiction_pairs = torch.mv(tableau[\"sentence_pair_row\"], r) == tableau[\"contradiction_labels\"]\n",
    "    \n",
    "    branches = copy.copy(tableau[\"branches\"])\n",
    "    \n",
    "    for i, pair in enumerate(tableau[\"pairs\"]):\n",
    "        if is_contradiction_pairs[i] == True:\n",
    "            for branch in branches:\n",
    "                if pair[0] in branch and pair[1] in branch:\n",
    "                    branches.remove(branch)\n",
    "    return len(branches) == 0\n",
    "\n",
    "def predict_label(sample, r):\n",
    "    is_close_entailment_tableau = is_close_tableau(sample[\"entailment_tableau\"], r)\n",
    "    is_close_contradiction_tableau = is_close_tableau(sample[\"contradiction_tableau\"], r)\n",
    "    if is_close_entailment_tableau == True and is_close_contradiction_tableau == False:\n",
    "        return 0\n",
    "    elif is_close_entailment_tableau == False and is_close_contradiction_tableau == False:\n",
    "        return 1\n",
    "    elif is_close_entailment_tableau == False and is_close_contradiction_tableau == True:\n",
    "        return 2\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09d3d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predicted_labels = []\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm(target_dataset):\n",
    "        if sample[\"sentence_pair_size\"] > 0:\n",
    "            pairs_probs = torch.from_numpy(predict(sample[\"premises\"], sample[\"hypothesises\"])).to(device)\n",
    "            r = torch.argmax(pairs_probs, dim=1).float()\n",
    "            predicted_label = predict_label(sample, r)\n",
    "        else:\n",
    "            predicted_label = 1\n",
    "        \n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "tableau_predicted_labels = np.array(predicted_labels)\n",
    "tableau_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82b5e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"acc: {:.3f}%\".format(100 * (tableau_predicted_labels == gold_labels).sum() / len(TARGET_DF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb199697",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"err: {:.3f}%\".format(100 * (tableau_predicted_labels == -1).sum() / len(TARGET_DF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6af9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(gold_labels, tableau_predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
